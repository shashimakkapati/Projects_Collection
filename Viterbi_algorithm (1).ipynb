{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f7923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_pos import get_word_tag, preprocess  \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e351e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few items of the training corpus list\n",
      "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n', 'of\\tIN\\n', '``\\t``\\n', 'The\\tDT\\n', 'Misanthrope\\tNN\\n', \"''\\t''\\n\", 'at\\tIN\\n', 'Chicago\\tNNP\\n', \"'s\\tPOS\\n\", 'Goodman\\tNNP\\n', 'Theatre\\tNNP\\n', '(\\t(\\n', '``\\t``\\n', 'Revitalized\\tVBN\\n', 'Classics\\tNNS\\n', 'Take\\tVBP\\n', 'the\\tDT\\n', 'Stage\\tNN\\n', 'in\\tIN\\n', 'Windy\\tNNP\\n', 'City\\tNNP\\n', ',\\t,\\n', \"''\\t''\\n\", 'Leisure\\tNN\\n', '&\\tCC\\n', 'Arts\\tNNS\\n', ')\\t)\\n', ',\\t,\\n', 'the\\tDT\\n', 'role\\tNN\\n', 'of\\tIN\\n', 'Celimene\\tNNP\\n', ',\\t,\\n', 'played\\tVBN\\n', 'by\\tIN\\n', 'Kim\\tNNP\\n', 'Cattrall\\tNNP\\n', ',\\t,\\n', 'was\\tVBD\\n', 'mistakenly\\tRB\\n', 'attributed\\tVBN\\n', 'to\\tTO\\n', 'Christina\\tNNP\\n', 'Haag\\tNNP\\n', '.\\t.\\n', '\\n', 'Ms.\\tNNP\\n', 'Haag\\tNNP\\n', 'plays\\tVBZ\\n', 'Elianti\\tNNP\\n', '.\\t.\\n', '\\n', 'Rolls-Royce\\tNNP\\n', 'Motor\\tNNP\\n', 'Cars\\tNNPS\\n', 'Inc.\\tNNP\\n', 'said\\tVBD\\n', 'it\\tPRP\\n', 'expects\\tVBZ\\n', 'its\\tPRP$\\n', 'U.S.\\tNNP\\n', 'sales\\tNNS\\n', 'to\\tTO\\n', 'remain\\tVB\\n', 'steady\\tJJ\\n', 'at\\tIN\\n', 'about\\tIN\\n', '1,200\\tCD\\n', 'cars\\tNNS\\n', 'in\\tIN\\n', '1990\\tCD\\n', '.\\t.\\n', '\\n', 'The\\tDT\\n', 'luxury\\tNN\\n', 'auto\\tNN\\n', 'maker\\tNN\\n', 'last\\tJJ\\n', 'year\\tNN\\n', 'sold\\tVBD\\n', '1,214\\tCD\\n', 'cars\\tNNS\\n', 'in\\tIN\\n', 'the\\tDT\\n', 'U.S.\\tNNP\\n', '\\n', 'Howard\\tNNP\\n', 'Mosher\\tNNP\\n', ',\\t,\\n', 'president\\tNN\\n', 'and\\tCC\\n', 'chief\\tJJ\\n', 'executive\\tNN\\n', 'officer\\tNN\\n', ',\\t,\\n', 'said\\tVBD\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    training_corpus = f.readlines()\n",
    "\n",
    "print(f\"A few items of the training corpus list\")\n",
    "print(training_corpus[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd34ba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A few items of the vocabulary list\n",
      "['!', '#', '$', '%', '&', \"'\", \"''\", \"'40s\", \"'60s\", \"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\", \"'n'\", \"'re\", \"'s\", \"'til\", \"'ve\", '(', ')', ',', '-', '--', '--n--', '--unk--', '--unk_adj--', '--unk_adv--', '--unk_digit--', '--unk_noun--', '--unk_punct--', '--unk_upper--', '--unk_verb--', '.', '...', '0.01', '0.0108', '0.02', '0.03', '0.05', '0.1', '0.10', '0.12', '0.13', '0.15']\n",
      "\n",
      "A few items at the end of the vocabulary list\n",
      "['yards', 'yardstick', 'year', 'year-ago', 'year-before', 'year-earlier', 'year-end', 'year-on-year', 'year-round', 'year-to-date', 'year-to-year', 'yearlong', 'yearly', 'years', 'yeast', 'yelled', 'yelling', 'yellow', 'yen', 'yes', 'yesterday', 'yet', 'yield', 'yielded', 'yielding', 'yields', 'you', 'young', 'younger', 'youngest', 'youngsters', 'your', 'yourself', 'youth', 'youthful', 'yuppie', 'yuppies', 'zero', 'zero-coupon', 'zeroing', 'zeros', 'zinc', 'zip', 'zombie', 'zone', 'zones', 'zoning', '{', '}', '']\n"
     ]
    }
   ],
   "source": [
    "with open(\"hmm_vocab.txt\", 'r') as f:\n",
    "    voc = f.read().split('\\n')\n",
    "\n",
    "print(\"A few items of the vocabulary list\")\n",
    "print(voc[0:50])\n",
    "print()\n",
    "print(\"A few items at the end of the vocabulary list\")\n",
    "print(voc[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a8747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "# Punctuation characters\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "# Morphology rules used to assign unknown word tokens\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c5f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unk(tok):\n",
    "    \"\"\"\n",
    "    Assign unknown word tokens\n",
    "    \"\"\"\n",
    "    # Digits\n",
    "    if any(char.isdigit() for char in tok):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Punctuation\n",
    "    elif any(char in punct for char in tok):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Upper-case\n",
    "    elif any(char.isupper() for char in tok):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Nouns\n",
    "    elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Verbs\n",
    "    elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Adjectives\n",
    "    elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Adverbs\n",
    "    elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "\n",
    "    return \"--unk--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b60f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab,txt_path):\n",
    "    orig=[]\n",
    "    processed=[]\n",
    "    with open(txt_path,\"r\") as f:\n",
    "        for cnt,word in enumerate(f):\n",
    "            \n",
    "            if not word.strip():\n",
    "                orig.append(\"--n--\")\n",
    "                processed.append(\"--n--\")\n",
    "            elif word.strip() not in vocab:\n",
    "                orig.append(word.strip())\n",
    "                word=assign_unk(word)\n",
    "                processed.append(word.strip())\n",
    "                continue\n",
    "            else:\n",
    "                orig.append(word.strip())\n",
    "                processed.append(word.strip())\n",
    "    return orig,processed\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90bf05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n"
     ]
    }
   ],
   "source": [
    "_, prep = preprocess(voc, \"test.words\") \n",
    "print(prep[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6b1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocab): \n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "        return word, tag\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocab: \n",
    "            # Handle unknown words\n",
    "            word = assign_unk(word)\n",
    "        return word, tag\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44de77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('review', 'NN')\n"
     ]
    }
   ],
   "source": [
    "print(get_word_tag(\"review\\tNN\\n\",voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1144b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(corpus,vocab):\n",
    "    prev_tag=\"--s--\"\n",
    "    trans=defaultdict(int)\n",
    "    emis=defaultdict(int)\n",
    "    tag_count=defaultdict(int)\n",
    "    i=0\n",
    "    for k in corpus:\n",
    "        i+=1\n",
    "        if i%50000==0:\n",
    "            print(i)\n",
    "        \n",
    "        word,tag=get_word_tag(k,vocab)\n",
    "        trans[(prev_tag,tag)]+=1\n",
    "        emis[(tag,word)]+=1\n",
    "        tag_count[tag]+=1\n",
    "        prev_tag=tag\n",
    "    return trans,emis,tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2895e67f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "450000\n",
      "500000\n",
      "550000\n",
      "600000\n",
      "650000\n",
      "700000\n",
      "750000\n",
      "800000\n",
      "850000\n",
      "900000\n",
      "950000\n"
     ]
    }
   ],
   "source": [
    "trans,emis,tag_count=trainer(training_corpus,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d919bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'IN': 98554, 'DT': 81842, 'NNP': 91466, 'CD': 36568, 'NN': 132935, '``': 7092, \"''\": 6919, 'POS': 8701, '(': 1366, 'VBN': 20024, 'NNS': 59856, 'VBP': 12491, ',': 48727, 'CC': 23947, ')': 1376, 'VBD': 29889, 'RB': 30970, 'TO': 22357, '.': 39478, '--s--': 39832, 'VBZ': 21672, 'NNPS': 2673, 'PRP': 17436, 'PRP$': 8407, 'VB': 26438, 'JJ': 61217, 'MD': 9803, 'VBG': 14846, 'RBR': 1768, ':': 4772, 'WP': 2363, 'WDT': 4294, 'JJR': 3238, 'PDT': 370, 'RBS': 451, 'WRB': 2143, 'JJS': 1947, '$': 7372, 'RP': 2662, 'FW': 234, 'EX': 863, 'SYM': 58, '#': 142, 'LS': 36, 'UH': 97, 'WP$': 168})\n"
     ]
    }
   ],
   "source": [
    "print(tag_count)\n",
    "states = sorted(tag_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6903304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prep,vocab,trans,tagz,emis):\n",
    "    \n",
    "    k=0\n",
    "    \n",
    "    for word,y_tup in zip(prep,y):\n",
    "        if len(y_tup.split())!=2:\n",
    "            \n",
    "            continue\n",
    "        else:\n",
    "            true=y_tup.split()[1]\n",
    "            \n",
    "        pred_key=\"\"\n",
    "        if word in vocab:\n",
    "            pos=0\n",
    "            for key in tagz:\n",
    "                if (key,word) not in emis.keys():\n",
    "                    \n",
    "                    continue\n",
    "                elif pos<emis[(key,word)]:\n",
    "                    pos=emis[(key,word)]\n",
    "                    pred_key=key\n",
    "            if pred_key==true:\n",
    "              k=k+1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return k/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8dadad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n', 'be\\tVB\\n', 'taken\\tVBN\\n', 'from\\tIN\\n', 'several\\tJJ\\n', 'vantage\\tNN\\n', 'points\\tNNS\\n', 'this\\tDT\\n', 'week\\tNN\\n', ',\\t,\\n', 'with\\tIN\\n', 'readings\\tNNS\\n', 'on\\tIN\\n', 'trade\\tNN\\n', ',\\t,\\n', 'output\\tNN\\n', ',\\t,\\n', 'housing\\tNN\\n', 'and\\tCC\\n', 'inflation\\tNN\\n', '.\\t.\\n', '\\n', 'The\\tDT\\n', 'most\\tRBS\\n', 'troublesome\\tJJ\\n', 'report\\tNN\\n', 'may\\tMD\\n', 'be\\tVB\\n', 'the\\tDT\\n', 'August\\tNNP\\n', 'merchandise\\tNN\\n', 'trade\\tNN\\n', 'deficit\\tNN\\n', 'due\\tJJ\\n', 'out\\tIN\\n', 'tomorrow\\tNN\\n', '.\\t.\\n', '\\n', 'The\\tDT\\n', 'trade\\tNN\\n', 'gap\\tNN\\n', 'is\\tVBZ\\n', 'expected\\tVBN\\n', 'to\\tTO\\n', 'widen\\tVB\\n', 'to\\tTO\\n', 'about\\tIN\\n', '$\\t$\\n', '9\\tCD\\n', 'billion\\tCD\\n', 'from\\tIN\\n', 'July\\tNNP\\n', \"'s\\tPOS\\n\", '$\\t$\\n', '7.6\\tCD\\n', 'billion\\tCD\\n', ',\\t,\\n', 'according\\tVBG\\n', 'to\\tTO\\n', 'a\\tDT\\n', 'survey\\tNN\\n', 'by\\tIN\\n', 'MMS\\tNNP\\n', 'International\\tNNP\\n', ',\\t,\\n', 'a\\tDT\\n', 'unit\\tNN\\n', 'of\\tIN\\n', 'McGraw-Hill\\tNNP\\n', 'Inc.\\tNNP\\n', ',\\t,\\n', 'New\\tNNP\\n', 'York\\tNNP\\n', '.\\t.\\n', '\\n', 'Thursday\\tNNP\\n', \"'s\\tPOS\\n\", 'report\\tNN\\n', 'on\\tIN\\n', 'the\\tDT\\n', 'September\\tNNP\\n', 'consumer\\tNN\\n', 'price\\tNN\\n', 'index\\tNN\\n', 'is\\tVBZ\\n', 'expected\\tVBN\\n', 'to\\tTO\\n', 'rise\\tVB\\n', ',\\t,\\n', 'although\\tIN\\n', 'not\\tRB\\n', 'as\\tRB\\n', 'sharply\\tRB\\n', 'as\\tIN\\n', 'the\\tDT\\n', '0.9\\tCD\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"WSJ_24.pos\", 'r') as f:\n",
    "    y = f.readlines()\n",
    "print(y[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2cc391",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=predict(prep,voc,trans,states,emis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6daadeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888563993099213\n"
     ]
    }
   ],
   "source": [
    "print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473b505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae23e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac51dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagz=states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c8b09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transmat(alpha,tag_count,tagz,trans,emis):\n",
    "    mat=np.zeros((len(tagz),len(tagz)))\n",
    "    for i in range(len(tagz)):\n",
    "                   for j in range(len(tagz)):\n",
    "                      mat[i][j]=(trans[(tagz[i],tagz[j])]+alpha)/(tag_count[tagz[i]]+alpha*len(tagz))\n",
    "    return mat              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8e45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_trans=transmat(0.001,tag_count,tagz,trans,emis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb85d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emismat(alpha,tag_count,tagz,emis,voc):\n",
    "    mat=np.zeros((len(tagz),len(voc)))\n",
    "    for i in range(len(tagz)):\n",
    "        for j in range(len(voc)):\n",
    "            mat[i][j]=(emis[(tagz[i],voc[j])]+alpha)/(tag_count[tagz[i]]+alpha*len(voc))\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3284189",
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_mat=emismat(0.001,tag_count,tagz,emis,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc749346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ed987c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(states, tag_counts, trans_mat, emis_mat, corpus, vocab):\n",
    "    n=len(states)\n",
    "    best_probs=np.zeros((n,len(corpus)))\n",
    "    best_paths = np.zeros((n, len(corpus)))\n",
    "    s_idx = int(states.index(\"--s--\"))\n",
    "    for i in range(n):\n",
    "        if trans_mat[s_idx,i]==0:\n",
    "            best_probs[i][0]=-999999999999\n",
    "        else:\n",
    "            best_probs[i][0]=math.log(trans_mat[s_idx,i])+math.log(emis_mat[i,voc.index(corpus[0])])\n",
    "    return best_probs,best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce2e456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs,best_paths=initialize(states,tag_count,mat_trans,emis_mat,prep,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "488da3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(trans_mat, emismat, corpus, best_prob, best_paths, vocabulary):\n",
    "    n=best_prob.shape[0]\n",
    "    \n",
    "    for i in range(1,len(corpus)):\n",
    "        if i%1000==0:\n",
    "         print(i)\n",
    "        \n",
    "       \n",
    "        \n",
    "       \n",
    "        for j in range(n):\n",
    "            least=float('-inf')\n",
    "            best=None\n",
    "            for k in range(n):\n",
    "                \n",
    "                calc=best_prob[k][i-1]+math.log(trans_mat[k][j])+math.log(emismat[j][vocabulary[corpus[i]]])\n",
    "                if calc>least:\n",
    "                    least=calc\n",
    "                    best=k\n",
    "            best_probs[j][i]=least\n",
    "            best_paths[j][i]=best      \n",
    "    return best_probs,best_paths\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21170fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n"
     ]
    }
   ],
   "source": [
    "best_probs,best_paths=viterbi_forward(mat_trans, emis_mat, prep, best_probs, best_paths, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b183bad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-22.60982633          inf          inf ...          inf          inf\n",
      "           inf]\n",
      " [-23.07660654          inf          inf ...          inf          inf\n",
      "           inf]\n",
      " [-23.57298822          inf          inf ...          inf          inf\n",
      "           inf]\n",
      " ...\n",
      " [-22.75551606          inf          inf ...          inf          inf\n",
      "           inf]\n",
      " [-19.6637215           inf          inf ...          inf          inf\n",
      "           inf]\n",
      " [-18.36288463          inf          inf ...          inf          inf\n",
      "           inf]]\n"
     ]
    }
   ],
   "source": [
    "print(best_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    minprob=float('-inf')\n",
    "    m=len(corpus)\n",
    "    \n",
    "    pred = [None] * m\n",
    "    z=[None]*m\n",
    "    tag=0\n",
    "    for i in range(best_probs.shape[0]):\n",
    "        if best_probs[i,-1]<minprob:\n",
    "            minprob=best_probs[i,-1]\n",
    "            z[m-1]=i\n",
    "            pred[m-1]=states[i]\n",
    "    for i in range(len(corpus)-1,-1,-1):\n",
    "        z[i-1]=best_paths[z[i],i]\n",
    "        pred[i-1]=states[i-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46e4e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    m = len(corpus)\n",
    "    z = [None] * m\n",
    "    pred = [None] * m\n",
    "    \n",
    "    # Step 1: Find best POS tag index for the last word\n",
    "    maxprob = float('-inf')\n",
    "    for i in range(best_probs.shape[0]):\n",
    "        if best_probs[i, -1] > maxprob:\n",
    "            maxprob = best_probs[i, -1]\n",
    "            z[m - 1] = i\n",
    "    pred[m - 1] = states[z[m - 1]]\n",
    "    \n",
    "    # Step 2: Walk backward to find the full best path\n",
    "    for i in range(m - 1, 0, -1):\n",
    "        z[i - 1] = best_paths[int(z[i]), i]\n",
    "        pred[i - 1] = states[int(z[i - 1])]\n",
    "    \n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84328611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=viterbi_backward(best_probs, best_paths, prep, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db1c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad5cd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, y):\n",
    "    '''\n",
    "    Input: \n",
    "        pred: a list of the predicted parts-of-speech \n",
    "        y: a list of lines where each word is separated by a '\\t' (i.e. word \\t tag)\n",
    "    Output: \n",
    "        \n",
    "    '''\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Zip together the prediction and the labels\n",
    "    for prediction, y in zip(pred, y):\n",
    "        ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "        # Split the label into the word and the POS tag\n",
    "        word_tag_tuple = y.split()\n",
    "        \n",
    "        # Check that there is actually a word and a tag\n",
    "        # no more and no less than 2 items\n",
    "        if len(word_tag_tuple)!=2: # complete this line\n",
    "            continue \n",
    "\n",
    "        # store the word and tag separately\n",
    "        word, tag = word_tag_tuple\n",
    "        \n",
    "        # Check if the POS tag label matches the prediction\n",
    "        if prediction == tag: # complete this line\n",
    "            \n",
    "            # count the number of times that the prediction\n",
    "            # and label match\n",
    "            num_correct += 1\n",
    "            \n",
    "        # keep track of the total number of examples (that have valid labels)\n",
    "        total += 1\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "    return num_correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1672df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953063647155511\n"
     ]
    }
   ],
   "source": [
    "print(compute_accuracy(pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4da55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
