{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0468a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v3 import *\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746ed5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('train_catvnoncat.h5')\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_catvnoncat.h5')\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de99aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes=load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337c2553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209) (1, 209)\n"
     ]
    }
   ],
   "source": [
    "train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255\n",
    "test_x = test_x_flatten/255\n",
    "print(train_x.shape,train_set_y_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intialize_parameters(n_x,n_y,n_h):\n",
    "    w1=np.random.randn(n_h,n_x)\n",
    "    b1=np.zeros((n_h,1))\n",
    "    w2=np.random.randn(n_y,n_h)\n",
    "    b2=np.zeros((n_y,1))\n",
    "    return w1,b1,w2,b2\n",
    "def relu(Z):\n",
    "    F=np.maximum(0,Z)\n",
    "    cache=Z\n",
    "    return F,Z\n",
    "def linear_forward(A_prev,W,b,activation):\n",
    "    Z=W.dot(A_prev)+b\n",
    "    if activation==\"relu\":\n",
    "        \n",
    "        \n",
    "        F,Z=relu(Z)\n",
    "        return F,Z,A_prev,W,b\n",
    "    else:\n",
    "        Z = np.clip(Z, -500, 500)\n",
    "        sig=1/(1+np.exp(-Z))\n",
    "        return sig,Z,A_prev,W,b\n",
    "def linear_backward(dA,Z,W,b,activation,A):\n",
    "    if activation==\"relu\":\n",
    "        \n",
    "        dZ = np.array(dA, copy=True) \n",
    "        dZ[Z <= 0] = 0 \n",
    "    else:\n",
    "        s = 1/(1+np.exp(-Z))\n",
    "        dZ = dA * s * (1-s)\n",
    "    m = dA.shape[1]\n",
    "    \n",
    "    dW = 1./m * np.dot(dZ,A.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35607e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdf5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t monokai -T -N -kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814e17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_forward(X,parameters):\n",
    "    A=X\n",
    "    \n",
    "    \n",
    "    A_cache=[]\n",
    "    l=len(parameters)\n",
    "    for i in range(l-1):\n",
    "        A_prev=A\n",
    "        A_cache.append(A)\n",
    "        A,p,q,w1,b1=linear_forward(A_prev,parameters[i][0],parameters[i][1],\"relu\")\n",
    "        \n",
    "    A_cache.append(A)\n",
    "    AL,p,q,w1,b1=linear_forward(A,parameters[l-1][0],parameters[l-1][1],\"sig\")\n",
    "    A_cache.append(A)\n",
    "    return AL,A_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a4cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \n",
    "    \n",
    "    \n",
    "    parameters = []\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for i in range(0, L-1):\n",
    "        w1 = np.random.randn(layer_dims[i+1], layer_dims[i]) * np.sqrt(2/layer_dims[i]) #*0.01\n",
    "        b1 = np.zeros((layer_dims[i+1], 1))\n",
    "        parameters.append([w1,b1])\n",
    "        \n",
    "        \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cb40aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [12288, 20, 7, 5, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb52952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_backward(Y,A_mat,AL,caches):\n",
    "    L = len(A_mat)\n",
    "    \n",
    "    grads=[]\n",
    "    dAL = - (np.divide(Y, AL+0.000001) - np.divide(1 - Y, 1 - AL+0.000001))\n",
    "    da_prev,dw,db=linear_backward(dAL,caches[L-2][0].dot(A_mat[L-2])+caches[L-2][1],caches[L-2][0],caches[L-2][1],\"sig\",A_mat[L-2])    \n",
    "    grads.append([dw,db])\n",
    "    for i in range(1,L-1):\n",
    "        \n",
    "        da_prev,dw,db=linear_backward(da_prev,caches[L-2-i][0].dot(A_mat[L-2-i])+caches[L-2-i][1],caches[L-2-i][0],caches[L-2-i][1],\"relu\",A_mat[L-2-i])\n",
    "        grads.append([dw,db])\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58308354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_l(X,Y,layer_dims,alpha,itera):\n",
    "    pr=initialize_parameters_deep(layer_dims)\n",
    "    for i in range(itera):\n",
    "        AL,Z_cache=L_forward(X,pr)\n",
    "        \n",
    "        \n",
    "        grads=l_backward(Y,Z_cache,AL,pr)\n",
    "        for p in range(0,len(pr)):\n",
    "            \n",
    "            pr[p][0]=pr[p][0]-alpha*grads[-(p+1)][0]\n",
    "            pr[p][1]=pr[p][1]-alpha*grads[-(p+1)][1]\n",
    "    return pr,AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282a2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_l_without_initial(X,Y,layer_dims,alpha,itera,pr):\n",
    "    for i in range(itera):\n",
    "        AL,Z_cache=L_forward(X,pr)\n",
    "        \n",
    "        \n",
    "        grads=l_backward(Y,Z_cache,AL,pr)\n",
    "        for p in range(0,len(pr)):\n",
    "            \n",
    "            pr[p][0]=pr[p][0]-alpha*grads[-(p+1)][0]\n",
    "            pr[p][1]=pr[p][1]-alpha*grads[-(p+1)][1]\n",
    "    return pr,AL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86684264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shash\\AppData\\Local\\Temp\\ipykernel_10164\\2225162652.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  q[0,i]=(AL[:,i]>0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7129186602870813"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr,AL=implement_l(train_x,train_set_y_orig,layer_dims,0.01,800)\n",
    "q = np.zeros((1,209))\n",
    "\n",
    "for i in range(AL.shape[1]):\n",
    "    q[0,i]=(AL[:,i]>0.5)\n",
    "\n",
    "np.sum(q==train_set_y_orig)/209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d2df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6e5a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(X,Y,batch_size):\n",
    "    \n",
    "    k=list(np.random.permutation(int(X.shape[1])))\n",
    "    shuff_x=X[:,k]\n",
    "    shuff_y=Y[:,k]\n",
    "    p=math.ceil(X.shape[1]/batch_size)\n",
    "    mini_batch_x=[]\n",
    "    mini_batch_y=[]\n",
    "    for i in range(p):\n",
    "        mini_batch_x.append(shuff_x[:,i*batch_size:i*batch_size+batch_size])\n",
    "        mini_batch_y.append(shuff_y[:,i*batch_size:i*batch_size+batch_size])\n",
    "    \n",
    "    batch = (mini_batch_x, mini_batch_y)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26cd46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=mini_batch(train_x,train_set_y_orig,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b4332c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.89323082e-03 6.66706414e-03 9.92127307e-01 9.95521848e-01\n",
      " 1.43361013e-02 1.85209879e-02 9.91545760e-01 9.74679580e-01\n",
      " 9.93150523e-01 9.81806476e-01 9.90498367e-01 4.26946842e-03\n",
      " 9.98101300e-01 1.53553646e-02 2.76545686e-02 1.57079634e-02\n",
      " 1.95029036e-02 5.32679897e-01 9.08206672e-03 6.06121540e-03\n",
      " 5.46616453e-03 1.71985570e-04 8.73768217e-04 5.32679897e-01\n",
      " 3.94969763e-03 5.74405456e-01 5.74405456e-01 9.32795290e-03\n",
      " 1.98726163e-02 5.74405456e-01 2.52401084e-02 1.16986607e-02\n",
      " 1.58181331e-03 3.31943582e-03 3.17528683e-03 4.14007527e-03\n",
      " 8.93730491e-03 9.84213772e-01 5.90389187e-01 1.04351683e-04\n",
      " 1.58187521e-03 2.75175383e-02 1.70658268e-03 9.71885866e-04\n",
      " 8.59911077e-03 6.19716905e-01 6.19716905e-01 1.68775047e-03\n",
      " 6.59842710e-01 6.59842710e-01 6.59842710e-01 6.59842710e-01\n",
      " 6.59842710e-01 6.59842710e-01 6.59842710e-01 6.59842710e-01\n",
      " 2.64336401e-02 9.32208474e-01 3.31213661e-02 6.17974534e-01\n",
      " 6.17974534e-01 2.76496846e-02 3.18702284e-02 3.62438046e-02\n",
      " 6.53257123e-01 4.80398269e-02 2.33908904e-02 1.75857130e-02\n",
      " 1.29745513e-02 3.37458576e-02 1.63258206e-02 6.53257123e-01\n",
      " 2.56737420e-03 9.87258152e-01 2.67106781e-03 4.72859145e-03\n",
      " 3.52050999e-03 2.89648586e-03 1.09978533e-02 6.56456163e-01\n",
      " 6.15937948e-04 2.30441014e-03 6.97010856e-01 6.44818424e-03\n",
      " 9.37945186e-04 1.88289975e-04 6.42316365e-03 6.97010856e-01\n",
      " 1.75897632e-03 3.14668284e-03 4.70637726e-05 6.18443648e-05\n",
      " 8.85840180e-06 1.42276430e-03 3.31209143e-05 4.89876069e-04\n",
      " 6.22589254e-01 6.22589254e-01 1.96368454e-03 6.22589254e-01\n",
      " 6.22589254e-01 6.22589254e-01 6.22589254e-01 6.22589254e-01\n",
      " 5.45240824e-01 5.45240824e-01 5.45240824e-01 5.45240824e-01\n",
      " 5.45240824e-01 5.45240824e-01 5.45240824e-01 5.45240824e-01\n",
      " 5.52929733e-01 4.61876378e-02 1.40706934e-03 5.52929733e-01\n",
      " 5.52929733e-01 1.45801538e-03 1.37533666e-02 5.52929733e-01\n",
      " 4.63854719e-01 4.63854719e-01 4.63854719e-01 4.63854719e-01\n",
      " 4.63854719e-01 4.63854719e-01 4.63854719e-01 4.63854719e-01\n",
      " 6.52364603e-03 8.62112661e-04 4.76162792e-01 4.69202953e-04\n",
      " 4.53529737e-03 1.77811107e-03 1.16568287e-04 2.18888268e-03\n",
      " 5.34101280e-01 5.34101280e-01 5.34101280e-01 5.34101280e-01\n",
      " 5.34101280e-01 3.32891097e-03 5.34101280e-01 2.52431718e-02\n",
      " 5.69837961e-01 1.02455113e-02 5.69837961e-01 1.46740415e-02\n",
      " 5.69837961e-01 5.69837961e-01 3.55261063e-03 5.69837961e-01\n",
      " 1.48901985e-04 6.96453580e-03 4.93293471e-01 4.93293471e-01\n",
      " 2.49428965e-02 4.93293471e-01 4.93293471e-01 4.93293471e-01\n",
      " 8.35929924e-07 9.81317130e-01 1.13908214e-03 5.53603851e-03\n",
      " 6.96977038e-03 5.19006745e-01 9.86284250e-04 5.54090591e-02\n",
      " 9.96751828e-01 5.54117905e-02 4.92043366e-01 1.17701156e-02\n",
      " 1.97450850e-02 4.92043366e-01 4.69195627e-01 4.92043366e-01\n",
      " 5.86223844e-01 4.06176175e-03 1.03348317e-02 5.86223844e-01\n",
      " 5.86223844e-01 8.78932930e-03 1.50757074e-02 9.59917639e-04\n",
      " 1.54317359e-03 4.43466143e-03 6.17314293e-01 9.96146497e-01\n",
      " 1.68930846e-02 4.18633871e-07 4.65682118e-04 6.17314293e-01\n",
      " 9.98231541e-01 6.54358450e-01 1.35258424e-02 6.54358450e-01\n",
      " 6.54358450e-01 1.42141769e-02 5.52507871e-09 2.91477371e-03\n",
      " 1.86163688e-02 6.57476777e-01 2.17651337e-03 8.64784891e-04\n",
      " 8.99102889e-04 6.58767026e-01 6.58767026e-01 6.58767026e-01\n",
      " 2.14727786e-04] [0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0\n",
      " 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 0\n",
      " 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "pr=initialize_parameters_deep(layer_dims)\n",
    "AL_final=[]\n",
    "\n",
    "batch=mini_batch(train_x,train_set_y_orig,8)\n",
    "o=[]\n",
    "for k in batch[1]:\n",
    "    o.append(k)\n",
    "shuffl_y=np.hstack(o)[0]\n",
    "AL_final=[]\n",
    "for i in range(len(batch[0])):\n",
    "     pr,AL=implement_l_without_initial(batch[0][i],batch[1][i],layer_dims,0.01,100,pr)\n",
    "     AL_final=AL_final+list(AL)\n",
    "final_a=(np.hstack(AL_final))\n",
    "print(final_a,shuffl_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c225e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba73edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.zeros((1,209))\n",
    "pred=[]\n",
    "for i in range(209):\n",
    "    if final_a[i]>0.5:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9791a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p=0\n",
    "for i in range(209):\n",
    "    if shuffl_y[i]==pred[i]:\n",
    "        p=p+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa0b9264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671e18f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
